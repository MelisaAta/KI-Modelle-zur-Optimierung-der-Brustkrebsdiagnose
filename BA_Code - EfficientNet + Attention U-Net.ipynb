{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4720c1",
   "metadata": {},
   "source": [
    "# BA: KI-gestützte Optimierung der Brustkrebsdiagnose: Automatisierte Tumorerkennung und Reduktion von Diagnosefehlern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07799fe2",
   "metadata": {},
   "source": [
    "### Benötigte Biblotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001946e0-6444-426b-a96e-aaf4376ec497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "# Filter für native CUDA/CUPTI-Warnings \n",
    "stderr = sys.stderr\n",
    "sys.stderr = open(os.devnull, 'w')  # Deaktiviert alles auf stderr (inkl. Delay-Kernel-Warnung)\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import shap\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, GlobalAveragePooling2D, Dense, Dropout,\n",
    "    BatchNormalization, Conv2D, UpSampling2D,\n",
    "    Concatenate, Multiply, Activation, Add, Layer)\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a133023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cd6b7",
   "metadata": {},
   "source": [
    "### 1. Daten laden und verarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Daten laden und verarbeiten\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel: Laden und Vorverarbeiten der DICOM-Bilddaten, ROI-Masken und klinischen Merkmale\n",
    "# Ergebnis: Speicherung der patientinnenbasierten Daten in verarbeiteten \"Chunks\"\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Pfade und Konfigurationsparameter\n",
    "\n",
    "EXCEL_PATH = \"/mnt/e/Advanced-MRI-Breast-Lesions/Advanced-MRI-Breast-Lesions-DA-Clinical-Sep2024.xlsx\"\n",
    "DICOM_FOLDER = \"/mnt/e/Advanced-MRI-Breast-Lesions/DICOM Images/manifest-1713182663002/Advanced-MRI-Breast-Lesions\"\n",
    "INTERMEDIATE_FOLDER = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/intermediate_caches\"\n",
    "os.makedirs(INTERMEDIATE_FOLDER, exist_ok=True)\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CHUNK_PATTERN = \"chunk_{:04d}.pkl\"\n",
    "MIN_MEAN_THRESHOLD = 0.0001  # minimale Maskenbedeckung pro Slice (Vermeidung leerer Masken)\n",
    "Z_TOLERANCE = 0.5            # maximal zulässiger Abstand (in mm) für Zuordnung von Masken zu Slices\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 1: Duplikate vermeiden – bereits verarbeitete Patientinnen laden\n",
    "\n",
    "processed_patient_ids = set()\n",
    "for file in sorted(os.listdir(INTERMEDIATE_FOLDER)):\n",
    "    if file.startswith(\"chunk_\") and file.endswith(\".pkl\"):\n",
    "        try:\n",
    "            with open(os.path.join(INTERMEDIATE_FOLDER, file), \"rb\") as f:\n",
    "                chunk = pickle.load(f)\n",
    "                processed_patient_ids.update(chunk.get(\"patient_ids\", []))\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von {file}: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 2: Klinische Daten laden und Feature-Mapping aufbauen\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH, header=1).fillna(0)\n",
    "\n",
    "# Auswahl: nur Patient ID, Alter, Tumor-Labels, Positionsdaten\n",
    "df_selected = df[[\n",
    "    \"Patient ID\", \"age at MRI\",\n",
    "    \"tumor/benign1\", \"pos1\", \"tumor/benign2\", \"pos2\",\n",
    "    \"tumor/benign3\", \"pos3\", \"tumor/benign4\", \"pos4\",\n",
    "    \"tumor/benign5\", \"pos5\", \"tumor/benign6\", \"pos6\"]].copy()\n",
    "\n",
    "# ------------------------------\n",
    "# Positionen in R/L-Koordinaten zerlegen \n",
    "import re\n",
    "def convert_position_value(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.match(r\"([RL])(-?\\d+\\.?\\d*)\", value)\n",
    "        if match:\n",
    "            side, number = match.groups()\n",
    "            number = float(number)\n",
    "            return (number, 0.0) if side == \"R\" else (0.0, number)\n",
    "    return (0.0, 0.0)\n",
    "\n",
    "def safe_convert_to_tuple(value):\n",
    "    result = convert_position_value(value)\n",
    "    return (round(result[0], 2), round(result[1], 2))\n",
    "\n",
    "for col in [\"pos1\", \"pos2\", \"pos3\", \"pos4\", \"pos5\", \"pos6\"]:\n",
    "    df_selected[f\"{col}_R\"] = df_selected[col].apply(lambda x: safe_convert_to_tuple(x)[0])\n",
    "    df_selected[f\"{col}_L\"] = df_selected[col].apply(lambda x: safe_convert_to_tuple(x)[1])\n",
    "df_selected.drop(columns=[\"pos1\", \"pos2\", \"pos3\", \"pos4\", \"pos5\", \"pos6\"], inplace=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Feature-Mapping pro Patient\n",
    "clinical_data_mapping = {\n",
    "    str(row[\"Patient ID\"]): row.drop(\"Patient ID\").values\n",
    "    for _, row in df_selected.iterrows()\n",
    "}\n",
    "patients_with_clinical = set(clinical_data_mapping.keys())\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 3: Hauptschleife – Verarbeitung der DICOM-Daten\n",
    "\n",
    "all_patients = sorted(os.listdir(DICOM_FOLDER))\n",
    "chunk_idx = 1\n",
    "\n",
    "for idx, patient_id in enumerate(all_patients):\n",
    "\n",
    "    # Nur Patientinnen mit klinischen Daten verarbeiten\n",
    "    if patient_id not in patients_with_clinical:\n",
    "        print(f\"[{idx+1}/{len(all_patients)}] {patient_id}: keine klinischen Daten – übersprungen.\")\n",
    "        continue\n",
    "\n",
    "    # Bereits verarbeitete Patientinnen überspringen\n",
    "    if patient_id in processed_patient_ids:\n",
    "        print(f\"[SKIP] Patientin {patient_id} bereits verarbeitet.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[{idx+1}/{len(all_patients)}] Verarbeite: {patient_id}\")\n",
    "\n",
    "    try:\n",
    "        # ----------------------------------------\n",
    "        # Unterordner bestimmen\n",
    "        ppath = os.path.join(DICOM_FOLDER, patient_id)\n",
    "        subs = [os.path.join(ppath, d) for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath, d))]\n",
    "        if not subs:\n",
    "            continue\n",
    "        patient_subfolder = subs[0]\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # ROI-Datei suchen\n",
    "        roi_file = None\n",
    "        for d in os.listdir(patient_subfolder):\n",
    "            if \"ROI\" in d.upper():\n",
    "                for fn in os.listdir(os.path.join(patient_subfolder, d)):\n",
    "                    if fn.lower().endswith(\".dcm\"):\n",
    "                        roi_file = os.path.join(patient_subfolder, d, fn)\n",
    "                        break\n",
    "            if roi_file:\n",
    "                break\n",
    "        if roi_file is None:\n",
    "            print(f\" -> Keine ROI gefunden für {patient_id} – übersprungen\")\n",
    "            continue\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # DICOM-Bilder laden (ohne ROI, ohne TRAM)\n",
    "        image_paths = []\n",
    "        for d in os.listdir(patient_subfolder):\n",
    "            if d.upper().startswith((\"ROI\", \"TRAM\")):\n",
    "                continue\n",
    "            sub = os.path.join(patient_subfolder, d)\n",
    "            if os.path.isdir(sub):\n",
    "                image_paths += [\n",
    "                    os.path.join(sub, f) for f in os.listdir(sub)\n",
    "                    if f.lower().endswith(\".dcm\")]\n",
    "        if not image_paths:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Z-Koordinaten extrahieren und sortieren\n",
    "        img_infos = []\n",
    "        for path in image_paths:\n",
    "            ds = pydicom.dcmread(path, stop_before_pixels=True)\n",
    "            if hasattr(ds, \"ImagePositionPatient\"):\n",
    "                z = float(ds.ImagePositionPatient[2])\n",
    "                img_infos.append((z, path))\n",
    "        if not img_infos:\n",
    "            continue\n",
    "\n",
    "        img_infos.sort(key=lambda x: x[0])\n",
    "        imgs, img_zs_fixed = [], []\n",
    "\n",
    "        for z, path in img_infos:\n",
    "            ds = pydicom.dcmread(path)\n",
    "            arr = ds.pixel_array.astype(np.float32)\n",
    "            arr = cv2.GaussianBlur(arr, (5, 5), sigmaX=1)\n",
    "            min_val, max_val = np.percentile(arr, 1), np.percentile(arr, 99)\n",
    "            arr = np.clip(arr, min_val, max_val)\n",
    "            arr = (arr - min_val) / (max_val - min_val + 1e-6)\n",
    "            imgs.append(np.rot90(arr, 2))\n",
    "            img_zs_fixed.append(z)\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # ROI-Masken aus DICOM extrahieren\n",
    "        ds_seg = pydicom.dcmread(roi_file)\n",
    "        seg_arr = ds_seg.pixel_array\n",
    "        seg_zs = [float(fg.PlanePositionSequence[0].ImagePositionPatient[2])\n",
    "                  for fg in ds_seg.PerFrameFunctionalGroupsSequence]\n",
    "        order = np.argsort(seg_zs)\n",
    "        seg_arr = seg_arr[order]\n",
    "        seg_zs = [seg_zs[i] for i in order]\n",
    "\n",
    "        # Zuweisung der Masken zu Slices nach Z-Toleranz\n",
    "        masks = []\n",
    "        for z in img_zs_fixed:\n",
    "            combined = np.zeros_like(seg_arr[0], dtype=np.uint8)\n",
    "            for seg_z, seg in zip(seg_zs, seg_arr):\n",
    "                if abs(seg_z - z) <= Z_TOLERANCE:\n",
    "                    combined |= (seg > 0).astype(np.uint8)\n",
    "            masks.append(np.rot90(combined, 2))\n",
    "        masks = np.stack(masks, axis=0)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Feature-Vektoren & Labels erstellen und Chunk speichern\n",
    "        image_data, mask_data, clinical_data = [], [], []\n",
    "        labels, image_patient_ids, roi_patient_ids, summary_table = [], [], [], []\n",
    "\n",
    "        row = df[df[\"Patient ID\"] == patient_id]\n",
    "        feats = clinical_data_mapping[patient_id]\n",
    "        flat_feats = []\n",
    "        for f in feats:\n",
    "            flat_feats.extend(f) if isinstance(f, tuple) else flat_feats.append(f)\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Schritt 1: Mapping Slice-Z -> Labels\n",
    "        added_count = 0\n",
    "        z_label_map = defaultdict(set)\n",
    "\n",
    "        \n",
    "        for i in range(1, 7):\n",
    "            label_col = f\"tumor/benign{i}\"\n",
    "            col_r = f\"pos{i}_R\"\n",
    "            col_l = f\"pos{i}_L\"\n",
    "\n",
    "            if label_col not in row or col_r not in df_selected or col_l not in df_selected:\n",
    "                continue\n",
    "\n",
    "            label_val = row[label_col].values[0]\n",
    "            r_val = df_selected.loc[df_selected[\"Patient ID\"] == patient_id, col_r].values[0]\n",
    "            l_val = df_selected.loc[df_selected[\"Patient ID\"] == patient_id, col_l].values[0]\n",
    "\n",
    "            z_target = r_val if r_val != 0.0 else l_val\n",
    "            if z_target == 0.0 or pd.isna(label_val):\n",
    "                continue\n",
    "\n",
    "            for z_val in img_zs_fixed:\n",
    "                if abs(z_val - z_target) <= Z_TOLERANCE:\n",
    "                    z_label_map[z_val].add(int(label_val))\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Schritt 2: Label-Vergabe auf Basis aller Z-Zuweisungen\n",
    "        for slice_idx, z_val in enumerate(img_zs_fixed):\n",
    "            if z_val not in z_label_map:\n",
    "                continue\n",
    "            label_set = z_label_map[z_val]\n",
    "            label = 1 if 1 in label_set else 0\n",
    "\n",
    "            img = imgs[slice_idx]\n",
    "            msk = masks[slice_idx]\n",
    "            if np.mean(msk) < MIN_MEAN_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            img_resized = np.expand_dims(cv2.resize(img, IMAGE_SIZE), axis=-1)\n",
    "            mask_resized = np.expand_dims(cv2.resize(msk, IMAGE_SIZE), axis=-1)\n",
    "\n",
    "            image_data.append(img_resized.astype(np.float32))\n",
    "            mask_data.append(mask_resized.astype(np.float32))\n",
    "            clinical_data.append(np.array(flat_feats, dtype=np.float32))\n",
    "            labels.append(label)\n",
    "            image_patient_ids.append(patient_id)\n",
    "            roi_patient_ids.append(patient_id)\n",
    "            added_count += 1\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Speicherung der Chunks und Datenzusammenfassung\n",
    "        if added_count == 0:\n",
    "            print(f\" -> Keine passenden Slices mit Label für {patient_id} gefunden.\")\n",
    "            continue\n",
    "\n",
    "        summary_table.append({\n",
    "            \"Patient ID\": patient_id,\n",
    "            \"Klinische Daten\": \"Ja\",\n",
    "            \"ROI Maske\": \"Ja\",\n",
    "            \"Bilder geladen\": added_count,\n",
    "            \"Masken geladen\": added_count,\n",
    "            \"Tumor/Benign\": f\"{added_count} Slices\"})\n",
    "\n",
    "        chunk_path = os.path.join(INTERMEDIATE_FOLDER, CHUNK_PATTERN.format(chunk_idx))\n",
    "        with open(chunk_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"images\": image_data,\n",
    "                \"masks\": mask_data,\n",
    "                \"clinical\": clinical_data,\n",
    "                \"labels\": labels,\n",
    "                \"roi_ids\": roi_patient_ids,\n",
    "                \"patient_ids\": image_patient_ids,\n",
    "                \"summary\": summary_table}, f)\n",
    "\n",
    "        print(f\" -> Gespeichert: {chunk_path}\")\n",
    "        chunk_idx += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei Patientin {patient_id}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edba30",
   "metadata": {},
   "source": [
    "#### 1.1 Zusammenführung der gespeicherten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ZUSAMMENFÜHRUNG DER VERARBEITETEN DATEN (Chunks)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel: Alle pro Patientin gespeicherten Daten-Chunks werden blockweise geladen\n",
    "#       und zu einem finalen Datensatz zusammengefügt\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Pfade für Zwischenspeicherung und finale Datenstruktur\n",
    "\n",
    "INTERMEDIATE_FOLDER = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/intermediate_caches\"\n",
    "FINAL_CACHE_FILE = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/geladene_Daten.pkl\"\n",
    "FINAL_SUMMARY_CSV = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/Datenzusammenfassung.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Initialisierung und Vorbereitung\n",
    "\n",
    "BLOCK_SIZE = 10  # Anzahl von Chunks pro Schreibblock (RAM-Effizienz)\n",
    "\n",
    "# Zielordner sicherstellen\n",
    "os.makedirs(os.path.dirname(FINAL_CACHE_FILE), exist_ok=True)\n",
    "\n",
    "# Alte finale Datei entfernen (Neustart)\n",
    "if os.path.exists(FINAL_CACHE_FILE):\n",
    "    os.remove(FINAL_CACHE_FILE)\n",
    "\n",
    "print(\"\\n -> Starte Zusammenführung der Chunks\")\n",
    "\n",
    "# Alle Chunk-Dateien im Zwischenspeicherordner sammeln\n",
    "chunk_files = sorted([\n",
    "    f for f in os.listdir(INTERMEDIATE_FOLDER)\n",
    "    if f.startswith(\"chunk_\") and f.endswith(\".pkl\")])\n",
    "print(f\" -> Gefundene Chunks: {len(chunk_files)}\")\n",
    "\n",
    "# Liste für zusammenfassende Informationen (später .csv)\n",
    "all_summary = []\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 1: Blöcke iterativ einlesen und final speichern\n",
    "\n",
    "with open(FINAL_CACHE_FILE, \"ab\") as final_f:\n",
    "\n",
    "    block_images = []\n",
    "    block_masks = []\n",
    "    block_clinical = []\n",
    "    block_labels = []\n",
    "    block_roi_ids = []\n",
    "    block_patient_ids = []\n",
    "\n",
    "    for idx, file in enumerate(chunk_files):\n",
    "        path = os.path.join(INTERMEDIATE_FOLDER, file)\n",
    "        print(f\"   -> Lade: {file} ({idx + 1}/{len(chunk_files)})\")\n",
    "\n",
    "        with open(path, \"rb\") as f:\n",
    "            chunk = pickle.load(f)\n",
    "\n",
    "        # Daten in temporäre Listen laden\n",
    "        block_images.extend(chunk[\"images\"])\n",
    "        block_masks.extend(chunk[\"masks\"])\n",
    "        block_clinical.extend(chunk[\"clinical\"])\n",
    "        block_labels.extend(chunk[\"labels\"])\n",
    "        block_roi_ids.extend(chunk[\"roi_ids\"])\n",
    "        block_patient_ids.extend(chunk[\"patient_ids\"])\n",
    "\n",
    "        # Summary-Einträge extrahieren und um Labeltext ergänzen\n",
    "        for summary_entry, label in zip(chunk[\"summary\"], chunk[\"labels\"]):\n",
    "            summary_entry[\"Tumorstatus\"] = f\"{int(label)} (Slice)\"\n",
    "            all_summary.append(summary_entry)\n",
    "\n",
    "        # Blockweise Speicherung zur Reduzierung des Speicherverbrauchs\n",
    "        if (idx + 1) % BLOCK_SIZE == 0 or (idx + 1) == len(chunk_files):\n",
    "            print(f\"      -> Speichere Block {idx // BLOCK_SIZE}\")\n",
    "\n",
    "            batch_data = {\n",
    "                \"images\": np.array(block_images, dtype=np.float32),\n",
    "                \"masks\": np.array(block_masks, dtype=np.float32),\n",
    "                \"clinical\": np.array(block_clinical, dtype=np.float32),\n",
    "                \"labels\": np.array(block_labels, dtype=np.float32),\n",
    "                \"roi_ids\": block_roi_ids,\n",
    "                \"patient_ids\": block_patient_ids}\n",
    "\n",
    "            pickle.dump(batch_data, final_f)\n",
    "\n",
    "            # Speicher freigeben\n",
    "            block_images.clear()\n",
    "            block_masks.clear()\n",
    "            block_clinical.clear()\n",
    "            block_labels.clear()\n",
    "            block_roi_ids.clear()\n",
    "            block_patient_ids.clear()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 2: Zusammenfassende CSV-Datei speichern\n",
    "\n",
    "print(\"\\n -> Speichere tabellarische Zusammenfassung\")\n",
    "\n",
    "df_summary = pd.DataFrame(all_summary)\n",
    "df_summary.to_csv(FINAL_SUMMARY_CSV, index=False)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 3: Statistik und Abschlussmeldung\n",
    "\n",
    "total_images = sum(entry[\"Bilder geladen\"] for entry in all_summary)\n",
    "total_masks = sum(entry[\"Masken geladen\"] for entry in all_summary)\n",
    "roi_patients = set(entry[\"Patient ID\"] for entry in all_summary)\n",
    "total_patients = roi_patients  # identisch, da alle mit ROI verarbeitet wurden\n",
    "\n",
    "print(\"\\n Zusammenführung abgeschlossen!\")\n",
    "print(f\"   * Bilder:             {total_images}\")\n",
    "print(f\"   * Masken:             {total_masks}\")\n",
    "print(f\"   * Klinikdaten:        {total_images} (1:1 mit Bildern)\")\n",
    "print(f\"   * Labels:             {total_images} (1:1 mit Bildern)\")\n",
    "print(f\"   * ROI-Patientinnen:   {len(roi_patients)}\")\n",
    "print(f\"   * Gesamt-Patientinnen:{len(total_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbd553",
   "metadata": {},
   "source": [
    "### 2. Prüfung der Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8188192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Prüfung und Visualisierung der Daten\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Geladene Daten auf Vollständigkeit, Konsistenz und Qualität prüfen\n",
    "#  - Labelverteilung visualisieren\n",
    "#  - Beispielbilder und klinische Informationen darstellen\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Relevante Dateipfade\n",
    "\n",
    "FINAL_CACHE_FILE = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/geladene_Daten.pkl\"\n",
    "FINAL_SUMMARY_CSV = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/Datenzusammenfassung.csv\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Funktion zum Laden des finalen Caches (mehrere Pickle-Blöcke)\n",
    "\n",
    "def load_final_cache(path):\n",
    "\n",
    "    data = {\n",
    "        \"images\": [],\n",
    "        \"masks\": [],\n",
    "        \"clinical\": [],\n",
    "        \"labels\": [],\n",
    "        \"roi_ids\": [],\n",
    "        \"patient_ids\": []}\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Cache nicht gefunden: {path}\")\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                batch = pickle.load(f)\n",
    "                data[\"images\"].append(batch[\"images\"])\n",
    "                data[\"masks\"].append(batch[\"masks\"])\n",
    "                data[\"clinical\"].append(batch[\"clinical\"])\n",
    "                data[\"labels\"].append(batch[\"labels\"])\n",
    "                data[\"roi_ids\"].extend(batch[\"roi_ids\"])\n",
    "                data[\"patient_ids\"].extend(batch[\"patient_ids\"])\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    # Stapelweise zu einem Array zusammenführen\n",
    "    data[\"images\"] = np.concatenate(data[\"images\"], axis=0)\n",
    "    data[\"masks\"] = np.concatenate(data[\"masks\"], axis=0)\n",
    "    data[\"clinical\"] = np.concatenate(data[\"clinical\"], axis=0)\n",
    "    data[\"labels\"] = np.concatenate(data[\"labels\"], axis=0)\n",
    "\n",
    "    return data\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 1: Laden und Übersicht\n",
    "\n",
    "print(\"\\n Lade finalen Cache\")\n",
    "cached = load_final_cache(FINAL_CACHE_FILE)\n",
    "\n",
    "# Entpacke Inhalte\n",
    "image_data = cached[\"images\"]\n",
    "mask_data = cached[\"masks\"]\n",
    "clinical_data = cached[\"clinical\"]\n",
    "labels = cached[\"labels\"]\n",
    "image_patient_ids = cached[\"patient_ids\"]\n",
    "roi_patient_ids = cached[\"roi_ids\"]\n",
    "\n",
    "print(\" Finaler Cache erfolgreich geladen!\")\n",
    "\n",
    "# Basisstatistiken\n",
    "print(\"\\n Datenübersicht:\")\n",
    "print(f\" * Bilder:             {image_data.shape}\")\n",
    "print(f\" * Masken:             {mask_data.shape}\")\n",
    "print(f\" * Klinikdaten:        {clinical_data.shape}\")\n",
    "print(f\" * Labels:             {labels.shape}\")\n",
    "print(f\" * ROI-Patientinnen:   {len(set(roi_patient_ids))}\")\n",
    "print(f\" * Gesamt-Patientinnen:{len(set(image_patient_ids))}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 2: Label-Verteilung\n",
    "\n",
    "def check_label_distribution(labels_array):\n",
    "\n",
    "    if labels_array is None or len(labels_array) == 0:\n",
    "        print(\"Keine Labels vorhanden – möglicherweise keine klinischen Daten?\")\n",
    "        return\n",
    "\n",
    "    if labels_array.ndim == 2 and labels_array.shape[1] == 2:\n",
    "        label_counts = np.sum(labels_array, axis=0)\n",
    "    else:\n",
    "        label_counts = np.array([\n",
    "            np.sum(labels_array == 0),\n",
    "            np.sum(labels_array == 1)])\n",
    "\n",
    "    categories = [\"Benigne\", \"Maligne\"]\n",
    "    plt.bar(categories, label_counts, color=[\"green\", \"red\"])\n",
    "    plt.xlabel(\"Kategorien\")\n",
    "    plt.ylabel(\"Anzahl Bilder\")\n",
    "    plt.grid(True, axis='y', linestyle='-', linewidth=0.6)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n Klassnverteilung:\")\n",
    "    print(f\" - Benigne: {int(label_counts[0])} Bilder\")\n",
    "    print(f\" - Maligne: {int(label_counts[1])} Bilder\")\n",
    "\n",
    "check_label_distribution(labels)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 3: Zufällige Bild-/Masken-Paare visualisieren\n",
    "\n",
    "def show_random_images(num_images=5, show_masks=True):\n",
    "\n",
    "    indices = np.random.choice(len(image_data), num_images, replace=False)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(5 * num_images, 5))\n",
    "\n",
    "    selected_patients = []\n",
    "    selected_labels = []\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = image_data[idx].squeeze()\n",
    "        msk = mask_data[idx].squeeze() if mask_data is not None else None\n",
    "\n",
    "        lab = np.argmax(labels[idx]) if labels.ndim == 2 else labels[idx]\n",
    "        label_text = \"Maligne\" if lab == 1 else \"Benigne\"\n",
    "\n",
    "        pid = image_patient_ids[idx] if idx < len(image_patient_ids) else \"Unbekannt\"\n",
    "        roi_status = \"ROI\" if pid in roi_patient_ids else \"Keine ROI\"\n",
    "\n",
    "        selected_patients.append(pid)\n",
    "        selected_labels.append(label_text)\n",
    "\n",
    "        axes[i].imshow(img, cmap=\"gray\")\n",
    "        if show_masks and msk is not None and np.any(msk):\n",
    "            axes[i].imshow(np.ma.masked_where(msk == 0, msk), cmap=\"spring\", alpha=0.4)\n",
    "        axes[i].set_title(f\"{pid}\\n{label_text} ({roi_status})\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return indices, selected_patients, selected_labels\n",
    "\n",
    "# Beispielaufruf\n",
    "indices, selected_patients, selected_labels = show_random_images(num_images=5, show_masks=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Schritt 4: Klinische Daten zu den Beispielbildern anzeigen\n",
    "\n",
    "def show_sample_clinical_data(indices, selected_patients, selected_labels):\n",
    "\n",
    "    if clinical_data is None or len(clinical_data) == 0:\n",
    "        print(\"Keine klinischen Daten vorhanden.\")\n",
    "        return\n",
    "\n",
    "    column_names = [\n",
    "    \"age at MRI\",\n",
    "    \"tumor/benign1\", \"pos1_R\", \"pos1_L\",\n",
    "    \"tumor/benign2\", \"pos2_R\", \"pos2_L\",\n",
    "    \"tumor/benign3\", \"pos3_R\", \"pos3_L\",\n",
    "    \"tumor/benign4\", \"pos4_R\", \"pos4_L\",\n",
    "    \"tumor/benign5\", \"pos5_R\", \"pos5_L\",\n",
    "    \"tumor/benign6\", \"pos6_R\", \"pos6_L\"]\n",
    "\n",
    "    clinical_samples = []\n",
    "    for idx, pid, lab in zip(indices, selected_patients, selected_labels):\n",
    "        if idx >= len(clinical_data):\n",
    "            continue\n",
    "        info = clinical_data[idx]\n",
    "        formatted = []\n",
    "        for col, val in zip(column_names, info):\n",
    "            if col == \"age at MRI\" or re.match(r\"pos\\d+_[RL]\", col):\n",
    "                try:\n",
    "                    formatted.append(round(float(val), 2))\n",
    "                except:\n",
    "                    formatted.append(val)\n",
    "            else:\n",
    "                formatted.append(val)\n",
    "        clinical_samples.append([pid, lab] + formatted)\n",
    "\n",
    "    df_clin = pd.DataFrame(clinical_samples, columns=[\"Patient ID\", \"Label\"] + column_names)\n",
    "    print(\"\\n Zufällig ausgewählte klinische Daten:\")\n",
    "    print(df_clin.to_string(index=False))\n",
    "\n",
    "# Aufruf für die zuvor gezeigten Bildbeispiele\n",
    "show_sample_clinical_data(indices, selected_patients, selected_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff21d55",
   "metadata": {},
   "source": [
    "### 3. Train/Val/Test-Split auf Patientinnenbasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Train/Validierung/Test-Split auf Basis der Patientinne\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Sicherstellung, dass Bilder einer Patientin nicht in mehreren Sets auftreten\n",
    "#  - Reproduzierbarer Split in Trainings-, Validierungs- und Testdaten\n",
    "#  - Speicherung und Wiederverwendung des Splits mittels Pickle-Datei\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Relevante Pfade\n",
    "\n",
    "FINAL_CACHE_FILE = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/geladene_Daten.pkl\"\n",
    "SPLIT_INDICES_FILE = \"/mnt/e/Advanced-MRI-Breast-Lesions/data/patient_split_indices.pkl\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Schritt 1: Split laden, falls bereits vorhanden\n",
    "\n",
    "if os.path.exists(SPLIT_INDICES_FILE):\n",
    "    print(\" Lade gespeicherte Split-Indizes...\")\n",
    "\n",
    "    with open(SPLIT_INDICES_FILE, \"rb\") as f:\n",
    "        split_data = pickle.load(f)\n",
    "\n",
    "    train_idx = split_data[\"train\"]\n",
    "    val_idx = split_data[\"val\"]\n",
    "    test_idx = split_data[\"test\"]\n",
    "\n",
    "    train_patients = split_data[\"train_patients\"]\n",
    "    val_patients = split_data[\"val_patients\"]\n",
    "    test_patients = split_data[\"test_patients\"]\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\" Erzeuge neuen Split...\")\n",
    "\n",
    "    # Geladene Patientendaten aus dem Pickle-Cache extrahieren\n",
    "    with open(FINAL_CACHE_FILE, \"rb\") as f:\n",
    "        data = {\n",
    "            \"images\": [],\n",
    "            \"masks\": [],\n",
    "            \"clinical\": [],\n",
    "            \"labels\": [],\n",
    "            \"roi_ids\": [],\n",
    "            \"patient_ids\": []\n",
    "        }\n",
    "        while True:\n",
    "            try:\n",
    "                batch = pickle.load(f)\n",
    "                data[\"images\"].append(batch[\"images\"])\n",
    "                data[\"masks\"].append(batch[\"masks\"])\n",
    "                data[\"clinical\"].append(batch[\"clinical\"])\n",
    "                data[\"labels\"].append(batch[\"labels\"])\n",
    "                data[\"roi_ids\"].extend(batch[\"roi_ids\"])\n",
    "                data[\"patient_ids\"].extend(batch[\"patient_ids\"])\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    all_patient_ids = np.array(data[\"patient_ids\"])\n",
    "    roi_patients = sorted(set(all_patient_ids))\n",
    "\n",
    "    print(f\" Anzahl ROI-Patientinnen gesamt: {len(roi_patients)}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Aufteilung in Train, Validation und Test (Verteilung: 70%, 15%, 15%)\n",
    "\n",
    "    train_patients, valtest_patients = train_test_split(\n",
    "        roi_patients, test_size=0.30, random_state=42, shuffle=True)\n",
    "\n",
    "    val_patients, test_patients = train_test_split(\n",
    "        valtest_patients, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Hilfsfunktion zur Umrechnung von Patientinnen-IDs in Bildindizes\n",
    "\n",
    "    def get_indices_by_patient_ids(all_ids, selected_ids):\n",
    "        selected_ids = set(selected_ids)\n",
    "        return [i for i, pid in enumerate(all_ids) if pid in selected_ids]\n",
    "\n",
    "    # Anwendung auf alle Sets\n",
    "    train_idx = get_indices_by_patient_ids(all_patient_ids, train_patients)\n",
    "    val_idx = get_indices_by_patient_ids(all_patient_ids, val_patients)\n",
    "    test_idx = get_indices_by_patient_ids(all_patient_ids, test_patients)\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Split-Daten zur Wiederverwendung speichern\n",
    "\n",
    "    with open(SPLIT_INDICES_FILE, \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"train\": train_idx,\n",
    "            \"val\": val_idx,\n",
    "            \"test\": test_idx,\n",
    "            \"train_patients\": train_patients,\n",
    "            \"val_patients\": val_patients,\n",
    "            \"test_patients\": test_patients,\n",
    "            \"roi_patients\": roi_patients}, f)\n",
    "\n",
    "    print(f\" Split-Indizes gespeichert unter: {SPLIT_INDICES_FILE}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Schritt 2: Zugriff auf die entsprechenden Bild- und Maskenarrays\n",
    "\n",
    "# Laden der Arrays aus Pickle\n",
    "with open(FINAL_CACHE_FILE, \"rb\") as f:\n",
    "    data = {\n",
    "        \"images\": [],\n",
    "        \"masks\": [],\n",
    "        \"clinical\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    while True:\n",
    "        try:\n",
    "            batch = pickle.load(f)\n",
    "            data[\"images\"].append(batch[\"images\"])\n",
    "            data[\"masks\"].append(batch[\"masks\"])\n",
    "            data[\"clinical\"].append(batch[\"clinical\"])\n",
    "            data[\"labels\"].append(batch[\"labels\"])\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "X_all_img = np.concatenate(data[\"images\"], axis=0)\n",
    "X_all_clinical = np.concatenate(data[\"clinical\"], axis=0)\n",
    "y_all = np.concatenate(data[\"labels\"], axis=0)\n",
    "mask_all = np.concatenate(data[\"masks\"], axis=0)\n",
    "\n",
    "X_train_img      = X_all_img[train_idx]\n",
    "X_val_img        = X_all_img[val_idx]\n",
    "X_test_img       = X_all_img[test_idx]\n",
    "\n",
    "X_train_clinical = X_all_clinical[train_idx]\n",
    "X_val_clinical   = X_all_clinical[val_idx]\n",
    "X_test_clinical  = X_all_clinical[test_idx]\n",
    "\n",
    "y_train = y_all[train_idx]\n",
    "y_val   = y_all[val_idx]\n",
    "y_test  = y_all[test_idx]\n",
    "\n",
    "mask_train = mask_all[train_idx]\n",
    "mask_val   = mask_all[val_idx]\n",
    "mask_test  = mask_all[test_idx]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Schritt 3: Übersicht über die Split-Verteilung\n",
    "\n",
    "print(\"\\n Übersicht Patientinnensplit (basierend auf ROI-Patientinnen):\")\n",
    "print(f\" * Train: {len(train_patients)} Patientinnen ({len(train_patients) / len(roi_patients):.2%})\")\n",
    "print(f\" * Val:   {len(val_patients)} Patientinnen ({len(val_patients) / len(roi_patients):.2%})\")\n",
    "print(f\" * Test:  {len(test_patients)} Patientinnen ({len(test_patients) / len(roi_patients):.2%})\")\n",
    "\n",
    "print(\"\\n Bildanzahl pro Split:\")\n",
    "print(f\" * Train: {len(train_idx)} Bilder\")\n",
    "print(f\" * Val:   {len(val_idx)} Bilder\")\n",
    "print(f\" * Test:  {len(test_idx)} Bilder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81263c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Konsistenzprüfung der Daten\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Sicherstellen, dass die geladenen Bilddaten keine NaN-Werte enthalten\n",
    "#  - NaNs (z.B. durch fehlerhafte Konvertierung oder Maskierung) werden durch 0 ersetzt\n",
    "#  - Diese Prüfung erfolgt für Trainings-, Validierungs- und Testbilder separat\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def validate_images(images, name=\"\"):\n",
    "\n",
    "    nan_count = np.isnan(images).sum()\n",
    "\n",
    "    if nan_count > 0:\n",
    "        print(f\" {name} enthält {nan_count} NaN-Werte – werden auf 0.0 gesetzt.\")\n",
    "        images = np.nan_to_num(images, nan=0.0)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Anwendung auf alle Bildsets\n",
    "X_train_img = validate_images(X_train_img, \"Train-Bilder\")\n",
    "X_val_img   = validate_images(X_val_img, \"Val-Bilder\")\n",
    "X_test_img  = validate_images(X_test_img, \"Test-Bilder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5568a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Prüfung der Maskenverteilung\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def analyze_mask_distribution_pickle(pkl_path, show_empty_count=True, svg_output_path=\"maskenverteilung.jpg\"):\n",
    "    # Masken aus Pickle laden\n",
    "    masks = []\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                batch = pickle.load(f)\n",
    "                masks.append(batch[\"masks\"])\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    masks = np.concatenate(masks, axis=0)\n",
    "    mask_sizes = np.array([np.sum(m > 0) for m in masks])\n",
    "\n",
    "    print(f\"Insgesamt {len(mask_sizes)} Masken analysiert\")\n",
    "    if show_empty_count:\n",
    "        empty = np.sum(mask_sizes == 0)\n",
    "        print(f\"{empty} Masken sind komplett leer (0 Pixel > 0)\")\n",
    "        print(f\"{np.sum(mask_sizes < 100)} Masken mit < 100 Tumor-Pixeln\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(mask_sizes, bins=50, color=\"blue\", edgecolor=\"black\")\n",
    "    plt.xlabel(\"Anzahl der Pixel pro Maske\")\n",
    "    plt.ylabel(\"Anzahl an Masken\")\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(svg_output_path, format=\"jpeg\")\n",
    "    plt.show()\n",
    "\n",
    "# Beispielaufruf\n",
    "analyze_mask_distribution_pickle(\"/mnt/e/Advanced-MRI-Breast-Lesions/data/geladene_Daten.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ca855",
   "metadata": {},
   "source": [
    "### 4. Multimodales Modell: CNN (EfficientNetB0) mit Transfer Learning für Klassifikation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------- \n",
    "# Klassifikationsmodell: EfficientNetB0 mit Bild + Klinikdaten + Focal Loss \n",
    "# ----------------------------------------------------------------------------- \n",
    "# Ziel: \n",
    "#  - Eingabebilder über EfficientNetB0 verarbeiten (ImageNet vortrainiert) \n",
    "#  - Kombination mit klinischen Merkmalen \n",
    "#  - Klassifikation mit Sigmoid-Ausgabe und robuster Focal Loss \n",
    "# ----------------------------------------------------------------------------- \n",
    "\n",
    "# ----------------------------------------------------------------------------- \n",
    "# Focal Loss \n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1. - tf.keras.backend.epsilon())\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        loss = -alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt)\n",
    "        return tf.reduce_mean(loss)\n",
    "    return loss_fn\n",
    "\n",
    "# ----------------------------------------------------------------------------- \n",
    "# EfficientNetB0 Multimodales Modell mit integrierter Bildaugmentierung\n",
    "def build_classification_model(image_input_shape=(256, 256, 3),\n",
    "                                clinical_input_shape=(19,),\n",
    "                                base_trainable_layers=80,\n",
    "                                dropout_rate=0.3,\n",
    "                                learning_rate=1e-3,\n",
    "                                l2_reg=1e-5,\n",
    "                                rotation_factor=0.2,\n",
    "                                zoom_factor=0.2,\n",
    "                                contrast_factor=0.2,\n",
    "                                brightness_factor=0.2,\n",
    "                                dense_units=(128, 64)):\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Bildeingabe definieren und Bildaugmentierung\n",
    "    image_input = Input(shape=image_input_shape, name=\"image_input\")\n",
    "\n",
    "    x = tf.keras.layers.Rescaling(1.0 / 255)(image_input)\n",
    "    x = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")(x)\n",
    "    x = tf.keras.layers.RandomRotation(rotation_factor)(x)\n",
    "    x = tf.keras.layers.RandomZoom(zoom_factor)(x)\n",
    "    x = tf.keras.layers.RandomContrast(contrast_factor)(x)\n",
    "    x = tf.keras.layers.RandomBrightness(factor=brightness_factor)(x)\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # EfficientNetB0 Backbone\n",
    "    x = preprocess_input(x)\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=x)\n",
    "\n",
    "    for layer in base_model.layers[:-base_trainable_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Zusätzliche Eingabe: klinische Merkmale\n",
    "    clinical_input = Input(shape=clinical_input_shape, name=\"clinical_input\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Kombination von Bild- und Klinikdaten\n",
    "    x = Concatenate()([x, clinical_input])\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Dichte Klassifikationsschichten\n",
    "    for units in dense_units:\n",
    "        x = Dense(units, activation=\"relu\", kernel_regularizer=l2(l2_reg))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Binäre Ausgabe\n",
    "    output = Dense(1, activation=\"sigmoid\", name=\"output\", dtype=\"float32\")(x)\n",
    "\n",
    "    model = Model(inputs=[image_input, clinical_input], outputs=output)\n",
    "\n",
    "    # ----------------------------------------------------------------------------- \n",
    "    # Modellkompilierung mit Focal Loss\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=focal_loss(),\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
    "\n",
    "    print(f\"Trainierbare Schichten in EfficientNetB0: {sum(layer.trainable for layer in base_model.layers)} / {len(base_model.layers)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2c42c",
   "metadata": {},
   "source": [
    "### 5. Attention U-Net mit EfficientNetB0 für Segmentierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Attention U-Net mit EfficientNetB0 für Segmentierung (Tumorerkennung)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Architektur zur pixelgenauen Segmentierung (Tumorregionen)\n",
    "#  - Kombination aus EfficientNetB0 als Encoder & U-Net Decoder mit Attention\n",
    "#  - RGB-Input-Erweiterung für Grayscale-MRT\n",
    "#  - Focal Tversky Loss \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Focal Tversky Loss \n",
    "\n",
    "def focal_tversky_loss(alpha=0.9, beta=0.1, gamma=1):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_f = tf.reshape(y_true, [-1])\n",
    "        y_pred_f = tf.reshape(y_pred, [-1])\n",
    "        TP = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "        FP = tf.reduce_sum((1 - y_true_f) * y_pred_f)\n",
    "        FN = tf.reduce_sum(y_true_f * (1 - y_pred_f))\n",
    "        tversky = (TP + 1e-6) / (TP + alpha * FN + beta * FP + 1e-6)\n",
    "        return tf.pow((1 - tversky), gamma)\n",
    "    return loss\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Attention-Modul für Skip-Verbindungen\n",
    "\n",
    "def attention_gate(x, g, filters):\n",
    "    theta_x = Conv2D(filters, 1, padding='same')(x)\n",
    "    phi_g = Conv2D(filters, 1, padding='same')(g)\n",
    "    add = Add()([theta_x, phi_g])\n",
    "    act = Activation('relu')(add)\n",
    "    psi = Conv2D(1, 1, padding='same', activation='sigmoid')(act)\n",
    "    return Multiply()([x, psi])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Benutzerdefinierte Lambda-Layer\n",
    "\n",
    "class ResizeLike(Layer):\n",
    "    def call(self, inputs):\n",
    "        source, target = inputs\n",
    "        target_shape = tf.shape(target)[1:3]\n",
    "        return tf.image.resize(source, size=target_shape, method='bilinear')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Encoder: Skip-Verbindungen aus EfficientNet\n",
    "\n",
    "def build_efficientnetb0_unet(input_shape=(256, 256, 3), \n",
    "                              dropout_rate=0.4, \n",
    "                              learning_rate=1e-4):\n",
    "    \n",
    "    base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n",
    "\n",
    "    skips = [\n",
    "        base_model.get_layer(\"block2a_activation\").output,  # 64x64\n",
    "        base_model.get_layer(\"block3a_activation\").output,  # 32x32\n",
    "        base_model.get_layer(\"block4a_activation\").output,  # 16x16\n",
    "        base_model.get_layer(\"block6a_activation\").output   # 8x8\n",
    "    ]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Bottleneck (z. B. block6d_activation statt output)\n",
    "\n",
    "    x = base_model.get_layer(\"block6d_activation\").output  # 7x7, tieferer Layer\n",
    "\n",
    "    x = Conv2D(1024, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Conv2D(1024, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Decoder\n",
    "\n",
    "    decoder_filters = [512, 256, 128, 64]\n",
    "\n",
    "    for i in range(4):\n",
    "        skip = skips[3 - i]  # reverse order: deepest skip first\n",
    "        x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)\n",
    "\n",
    "        skip_resized = ResizeLike()([skip, x])\n",
    "        attn = attention_gate(skip_resized, x, filters=skip.shape[-1])\n",
    "        x = Concatenate()([x, attn])\n",
    "        x = Conv2D(decoder_filters[i], 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Conv2D(decoder_filters[i], 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Ausgabeschicht\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(x)  # 64x64 → 128x128\n",
    "    outputs = Conv2D(1, 1, activation=\"sigmoid\", dtype=\"float32\", name=\"output_mask\")(x)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Modellkompilierung\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=focal_tversky_loss(alpha=0.9, beta=0.1, gamma=1),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Hilfsfunktion zur Konvertierung von Graustufenbildern zu RGB\n",
    "\n",
    "def convert_grayscale_to_rgb(images):\n",
    "    if images.ndim == 3:\n",
    "        images = np.expand_dims(images, axis=-1)\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.repeat(images, 3, axis=-1)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb6c13",
   "metadata": {},
   "source": [
    "### 6. Training und Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ed070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Trainingsprozess für Klassifikations- und Segmentierungsmodelle\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Universelle Trainingsfunktion für Klassifikation & Segmentierung \n",
    "#  - LearningRate-Reduktion, EarlyStopping, Checkpoints \n",
    "#  - Speicherung von History + Trainingszeit \n",
    "#  - Automatische Visualisierung \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train_and_evaluate(model,\n",
    "                       train_data,\n",
    "                       val_data=None,\n",
    "                       batch_size=None,\n",
    "                       epochs=25,\n",
    "                       is_segmentation=False,\n",
    "                       model_name=\"model\",\n",
    "                       patience=5,\n",
    "                       save_dir=\"training_output\",\n",
    "                       class_weight=None):\n",
    "\n",
    "    print(f\"\\n Training gestartet: {model_name}\\n\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Zeitmessung starten\n",
    "    start_time = time.time()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Zielordner für Ausgaben erstellen\n",
    "    checkpoint_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    history_dir = os.path.join(save_dir, \"history\")\n",
    "    plot_dir = os.path.join(save_dir, \"plots\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    print(f\" Speichern unter: {save_dir}\\n\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Callback-Setup\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, f\"{model_name}.keras\"),\n",
    "            monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=patience, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Trainingsfall 1: tf.keras.utils.Sequence (RAM-effizient)\n",
    "    if isinstance(train_data, tf.keras.utils.Sequence):\n",
    "        fit_args = {\n",
    "            \"validation_data\": val_data,\n",
    "            \"epochs\": epochs,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "\n",
    "        # class_weight nur bei Klassifikation (nicht Segmentierung!)\n",
    "        if class_weight and not is_segmentation:\n",
    "            fit_args[\"class_weight\"] = class_weight\n",
    "\n",
    "        history = model.fit(train_data, **fit_args)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Trainingsfall 2: NumPy-Daten (bei U-Net oder ohne Generator)\n",
    "    else:\n",
    "        if batch_size is None or val_data is None:\n",
    "            raise ValueError(\"Für NumPy-Daten müssen batch_size und val_data angegeben werden.\")\n",
    "\n",
    "        x_train, y_train = train_data\n",
    "        x_val, y_val = val_data\n",
    "\n",
    "        fit_args = {\n",
    "            \"x\": x_train,\n",
    "            \"y\": y_train,\n",
    "            \"validation_data\": (x_val, y_val),\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "\n",
    "        if class_weight and not is_segmentation:\n",
    "            fit_args[\"class_weight\"] = class_weight\n",
    "\n",
    "        history = model.fit(**fit_args) \n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Dauer & Verlauf speichern\n",
    "    duration_min = (time.time() - start_time) / 60\n",
    "    history_data = {\n",
    "        \"model_name\": model_name,\n",
    "        \"history\": history.history,\n",
    "        \"duration_min\": duration_min,\n",
    "        \"epochs_ran\": len(history.history.get(\"loss\", []))\n",
    "    }\n",
    "    hist_path = os.path.join(history_dir, f\"{model_name}_history.pkl\")\n",
    "    with open(hist_path, \"wb\") as f:\n",
    "        pickle.dump(history_data, f)\n",
    "\n",
    "    print(f\"\\n Trainingsverlauf gespeichert unter: {hist_path}\")\n",
    "    print(f\"  Dauer: {duration_min:.2f} Minuten\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Visualisierung der Trainingsmetriken\n",
    "    def plot_metric(metric_name):\n",
    "        train_values = history.history.get(metric_name)\n",
    "        val_values = history.history.get(f\"val_{metric_name}\")\n",
    "        if train_values is None or val_values is None:\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.plot(train_values, label=\"Train\", linewidth=2)\n",
    "        plt.plot(val_values, label=\"Val\", linewidth=2, linestyle=\"--\")\n",
    "        plt.xlabel(\"Epoche\")\n",
    "        plt.ylabel(metric_name.replace(\"_\", \" \").title())\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_axisbelow(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_path = os.path.join(plot_dir, f\"train_{model_name}_{metric_name}.jpg\")\n",
    "        plt.savefig(plot_path, format=\"svg\")\n",
    "        plt.show()\n",
    "        print(f\"{metric_name.title()}-Plot gespeichert unter: {plot_path}\")\n",
    "\n",
    "    for key in history.history:\n",
    "        if not key.startswith(\"val_\") and f\"val_{key}\" in history.history:\n",
    "            plot_metric(key)\n",
    "\n",
    "    return history, start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335efe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechnete class_weight: {0.0: 1.1904761904761905, 1.0: 0.8620689655172413}\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------\n",
    "# Exakte berechnung des Klassengleichgewichts\n",
    "#--------------------------------------------------------\n",
    "\n",
    "# Labels aus dem Generator extrahieren (einmalig pkl laden)\n",
    "with open(FINAL_CACHE_FILE, \"rb\") as f:\n",
    "    all_labels = []\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = pickle.load(f)\n",
    "            all_labels.extend(chunk[\"labels\"])\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "train_labels = all_labels[train_idx]\n",
    "\n",
    "# Gewicht pro Klasse berechnen (0 = benigne, 1 = maligne)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight = {cls: weight for cls, weight in zip(np.unique(train_labels), class_weights_array)}\n",
    "\n",
    "print(\"Berechnete class_weight:\", class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainierbare Schichten von beiden Modellen\n",
    "def print_trainable_layers(model, model_name=\"Modell\"):\n",
    "    total_layers = len(model.layers)\n",
    "    trainable_layers = sum(1 for layer in model.layers if layer.trainable)\n",
    "    print(f\"{model_name} – Trainierbare Schichten: {trainable_layers} / {total_layers}\")\n",
    "\n",
    "\n",
    "# Modell aufbauen (EfficientNet)\n",
    "classification_model = build_classification_model()\n",
    "classification_model.summary()\n",
    "print_trainable_layers(classification_model, \"Klassifikations Modell\")\n",
    "\n",
    "# U-Net aufbauen\n",
    "unet_model = build_efficientnetb0_unet()\n",
    "unet_model.summary()\n",
    "print_trainable_layers(unet_model, \"Attention U-Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858080d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Generator-Klasse für EfficientNet U-Net Segmentierung (RGB-kompatibel)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ziel:\n",
    "#  - Batchweise Bereitstellung von Bild + Maske\n",
    "#  - Synchronisierte Augmentierung (nur im Training)\n",
    "#  - Graustufen-Bilder → RGB\n",
    "#  - Filterung kleiner Masken (< min_mask_pixels)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class SegmentationDataGenerator(Sequence):\n",
    "    def __init__(self, images, masks,\n",
    "                 batch_size=8,\n",
    "                 augment=True,\n",
    "                 shuffle=True,\n",
    "                 rotation_range=5,\n",
    "                 zoom_range=0.05,\n",
    "                 horizontal_flip=True,\n",
    "                 vertical_flip=True,\n",
    "                 min_mask_pixels=100):\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Masken nach Mindestgröße filtern\n",
    "        valid_indices = [i for i in range(len(masks)) if np.sum(masks[i]) >= min_mask_pixels]\n",
    "        self.images = images[valid_indices]\n",
    "        self.masks = masks[valid_indices]\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.rotation_range = rotation_range\n",
    "        self.zoom_range = zoom_range\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.vertical_flip = vertical_flip\n",
    "\n",
    "        self.indices = np.arange(len(self.images))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Anzahl Batches pro Epoche\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / self.batch_size))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Einzelner Batch (Index)\n",
    "    def __getitem__(self, index):\n",
    "        idxs = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = self.images[idxs].copy()\n",
    "        Y_batch = self.masks[idxs].copy()\n",
    "\n",
    "        if self.augment:\n",
    "            X_batch_aug, Y_batch_aug = [], []\n",
    "            for x, y in zip(X_batch, Y_batch):\n",
    "                x_aug, y_aug = self.apply_augmentation(x, y)\n",
    "                X_batch_aug.append(x_aug)\n",
    "                Y_batch_aug.append(y_aug)\n",
    "            X_batch = np.stack(X_batch_aug)\n",
    "            Y_batch = np.stack(Y_batch_aug)\n",
    "\n",
    "        # Graustufenbilder -> RGB falls nötig\n",
    "        if X_batch.shape[-1] == 1:\n",
    "            X_batch = np.repeat(X_batch, 3, axis=-1)\n",
    "\n",
    "        return X_batch, Y_batch\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Shuffle der Daten nach jeder Epoche\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Synchronisierte Augmentierung für Bild + Maske\n",
    "    def apply_augmentation(self, x, y):\n",
    "        if self.horizontal_flip and random.random() < 0.5:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "\n",
    "        if self.vertical_flip and random.random() < 0.5:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "\n",
    "        if self.rotation_range:\n",
    "            angle = random.uniform(-self.rotation_range, self.rotation_range)\n",
    "            x = tf.keras.preprocessing.image.random_rotation(\n",
    "                x, self.rotation_range, row_axis=0, col_axis=1, channel_axis=2\n",
    "            )\n",
    "            y = tf.keras.preprocessing.image.random_rotation(\n",
    "                y, self.rotation_range, row_axis=0, col_axis=1, channel_axis=2\n",
    "            )\n",
    "\n",
    "        if self.zoom_range:\n",
    "            zx = 1 + random.uniform(-self.zoom_range, self.zoom_range)\n",
    "            zy = 1 + random.uniform(-self.zoom_range, self.zoom_range)\n",
    "            x = tf.keras.preprocessing.image.random_zoom(\n",
    "                x, (zx, zy), row_axis=0, col_axis=1, channel_axis=2\n",
    "            )\n",
    "            y = tf.keras.preprocessing.image.random_zoom(\n",
    "                y, (zx, zy), row_axis=0, col_axis=1, channel_axis=2\n",
    "            )\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a66c12",
   "metadata": {},
   "source": [
    "### 7. Modelltraining - EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc381bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Training – EfficientNetB0 Klassifikationsmodell\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nStarte Training des EfficientNetB0 Klassifikationsmodells:\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Modell aufbauen\n",
    "classification_model = build_classification_model(image_input_shape=(256, 256, 3))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Daten vorbereiten \n",
    "X_train_img = X_all_img[train_idx]\n",
    "X_val_img = X_all_img[val_idx]\n",
    "X_train_clinical = X_all_clinical[train_idx]\n",
    "X_val_clinical = X_all_clinical[val_idx]\n",
    "y_train = y_all[train_idx]\n",
    "y_val = y_all[val_idx]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Klassenverteilung anpassen\n",
    "class_weight = {\n",
    "    0.0: 1.2,\n",
    "    1.0: 0.8\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Modell trainieren + speichern\n",
    "history_classification, start_time_classification = train_and_evaluate(\n",
    "    model=classification_model,\n",
    "    train_data=([X_train_img, X_train_clinical], y_train),\n",
    "    val_data=([X_val_img, X_val_clinical], y_val),\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    is_segmentation=False,\n",
    "    model_name=\"efficientnet_model\",\n",
    "    patience=10,\n",
    "    save_dir=SAVE_DIR,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "classification_model.save(os.path.join(SAVE_DIR, \"efficientnet_model.keras\"))\n",
    "print(f\"EfficientNet Modell gespeichert unter: {os.path.join(SAVE_DIR, 'efficientnet_model.keras')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e44fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Training – Attention U-Net mit EfficientNetB0 (RGB Segmentierung mit Generator)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n Starte Training des EfficientNet U-Net Modells:\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Modell aufbauen\n",
    "unet_model = build_efficientnetb0_unet(input_shape=(256, 256, 3))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Daten vorbereiten\n",
    "X_train_img = X_all_img[train_idx]\n",
    "X_val_img = X_all_img[val_idx]\n",
    "Y_train = mask_all[train_idx]\n",
    "Y_val = mask_all[val_idx]\n",
    "\n",
    "# Kanal-Dimension sicherstellen\n",
    "if X_train_img.ndim == 3:\n",
    "    X_train_img = np.expand_dims(X_train_img, axis=-1)\n",
    "if X_val_img.ndim == 3:\n",
    "    X_val_img = np.expand_dims(X_val_img, axis=-1)\n",
    "if Y_train.ndim == 3:\n",
    "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
    "if Y_val.ndim == 3:\n",
    "    Y_val = np.expand_dims(Y_val, axis=-1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Generatoren definieren\n",
    "train_gen = SegmentationDataGenerator(X_train_img, Y_train, batch_size=4, augment=False)\n",
    "val_gen = SegmentationDataGenerator(X_val_img, Y_val, batch_size=4, augment=False)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Training starten (Generator als train_data)\n",
    "history_unet, start_time_unet = train_and_evaluate(\n",
    "    model=unet_model,\n",
    "    train_data=train_gen,\n",
    "    val_data=val_gen,\n",
    "    epochs=30,\n",
    "    is_segmentation=True,\n",
    "    model_name=\"efficientnet_unet\",\n",
    "    patience=5,\n",
    "    save_dir=SAVE_DIR\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Modell speichern\n",
    "unet_model.save(os.path.join(SAVE_DIR, \"efficientnet_unet_model.keras\"))\n",
    "print(f\"U-Net Modell gespeichert unter: {os.path.join(SAVE_DIR, 'efficientnet_unet_model.keras')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a46de",
   "metadata": {},
   "source": [
    "### 9. Evaluierung der Modelle EfficientNetB0 und Attention U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "#  Modell-Evaluierung \n",
    "# Ziel: \n",
    "# - Confusion Matrix, AUC- & ROC-Kurve für EfficientNet\n",
    "# - Dice-Score, IoU und visuallsierung der Masken\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Evaluierung: Klassifikation (EfficientNet) \n",
    "def evaluate_classification_model(model, X_test_img, y_test):\n",
    "    print(\"\\n Bewertung des Klassifikationsmodells gestartet\")\n",
    "\n",
    "    X_test_img_rgb = np.repeat(X_test_img, 3, axis=-1)\n",
    "    y_prob = model.predict([X_test_img_rgb, X_test_clinical], verbose=1).squeeze()\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "    print(f\" ROC-AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Falsch Positiv Rate\")\n",
    "    plt.ylabel(\"Richtig Positiv Rate\")\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/classification_roc.jpg\", format=\"jpeg\")\n",
    "    plt.show()\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Benigne\", \"Maligne\"], yticklabels=[\"Benigne\", \"Maligne\"])\n",
    "    plt.xlabel(\"Vorhergesagt\")\n",
    "    plt.ylabel(\"Tatsächlich\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/classification_confusion_matrix.jpg\", format=\"jpeg\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n Klassifikationsbericht:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Benigne\", \"Maligne\"], digits=2))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Evaluierung: Segmentierung (U-Net)\n",
    "def evaluate_segmentation_model(model, X_test_img, mask_test, num_examples=5):\n",
    "    print(\"\\n Bewertung des U-Net Segmentierungsmodells gestartet\")\n",
    "\n",
    "    preds = model.predict(X_test_img, batch_size=2, verbose=1)\n",
    "    preds_bin = (preds > 0.5).astype(np.uint8)\n",
    "\n",
    "    dice_scores, iou_scores = [], []\n",
    "    smooth = 1e-6\n",
    "\n",
    "    for true_mask, pred_mask in zip(mask_test, preds_bin):\n",
    "        true_f = true_mask.flatten()\n",
    "        pred_f = pred_mask.flatten()\n",
    "        intersection = np.sum(true_f * pred_f)\n",
    "        union = np.sum(true_f) + np.sum(pred_f)\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_scores.append(dice)\n",
    "        iou = jaccard_score(true_f, pred_f, zero_division=0)\n",
    "        iou_scores.append(iou)\n",
    "\n",
    "    print(f\" Dice Score (avg): {np.mean(dice_scores):.4f}\")\n",
    "    print(f\"  IoU Score  (avg): {np.mean(iou_scores):.4f}\")\n",
    "\n",
    "    print(\"\\n Beispielhafte Segmentierungen:\")\n",
    "    indices = np.random.choice(len(X_test_img), num_examples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axs[0].imshow(X_test_img[idx].squeeze(), cmap=\"gray\")\n",
    "        axs[0].set_title(\"Original\")\n",
    "        axs[1].imshow(mask_test[idx].squeeze(), cmap=\"Reds\")\n",
    "        axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(preds_bin[idx].squeeze(), cmap=\"Greens\")\n",
    "        axs[2].set_title(\"Vorhergesagt\")\n",
    "        for ax in axs:\n",
    "            ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        path = f\"plots/unet_example_{i}.jpg\"\n",
    "        plt.savefig(path, format=\"jpeg\")\n",
    "        plt.show()\n",
    "        print(f\"Beispiel gespeichert unter: {path}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Evaluierung starten\n",
    "evaluate_classification_model(classification_model, X_test_img, y_test)\n",
    "evaluate_segmentation_model(unet_model, X_test_img[..., :1], mask_test, num_examples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
